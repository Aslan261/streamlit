import streamlit as st
import pandas as pd
import networkx as nx
import plotly.graph_objects as go
import plotly.express as px
from collections import Counter
import re
from datetime import datetime
import math
import random  # Importado para gerar a aleatoriedade do plano

# Tenta importar a nova biblioteca do Google Gen AI
# Se o usu√°rio n√£o tiver instalado, o app n√£o quebra, mas avisa na aba
try:
    from google import genai
    from google.genai import types
    HAS_GENAI = True
except ImportError:
    HAS_GENAI = False

# Configura√ß√£o da P√°gina
st.set_page_config(page_title="B√≠blia Analytics", layout="wide", page_icon="üìñ")

# =========================================================
# 1. FUN√á√ïES DE CARREGAMENTO E PROCESSAMENTO
# =========================================================

@st.cache_data
def load_data(file):
    try:
        # Tenta ler como CSV padr√£o ou com separadores diferentes caso o usu√°rio mude o formato
        df = pd.read_csv(file)
        # Normaliza√ß√£o de nomes de colunas para garantir compatibilidade
        cols_map = {
            'Book Name': 'Livro', 
            'Book Number': 'Livro_ID', 
            'Chapter': 'Capitulo', 
            'Verse': 'Versiculo', 
            'Text': 'Texto',
            'Verse ID': 'ID_Global'
        }
        df.rename(columns=cols_map, inplace=True, errors='ignore')
        
        # Garante que colunas essenciais existam
        required_cols = ['Livro', 'Capitulo', 'Versiculo', 'Texto']
        if not all(col in df.columns for col in required_cols):
            st.error(f"O arquivo deve conter as colunas: {required_cols}")
            return None
            
        return df
    except Exception as e:
        st.error(f"Erro ao carregar arquivo: {e}")
        return None

# Lista b√°sica de stopwords e personagens para ajudar na extra√ß√£o simples
STOPWORDS_PT = set([
    'a', 'o', 'as', 'os', 'de', 'do', 'da', 'dos', 'das', 'em', 'no', 'na', 
    'nos', 'nas', 'por', 'pelo', 'pela', 'para', 'que', 'e', '√©', 'era', 
    'foi', 'com', 'sem', 'seu', 'sua', 'seus', 'suas', 'ele', 'ela', 'eles', 
    'elas', 'mas', 'ou', 'quando', 'como', 'onde', 'quem', 'porque', 'se', 
    'eu', 'tu', 'n√≥s', 'v√≥s', 'me', 'te', 'lhe', 'nos', 'vos', 'lhes', 
    'mim', 'ti', 'si', 'este', 'esta', 'isto', 'esse', 'essa', 'isso', 
    'aquele', 'aquela', 'aquilo', 'meu', 'teu', 'nosso', 'vosso', 'tua', 
    'minha', 'nossa', 'vossa', 'senhor', 'deus', 'jesus', 'cristo', 'n√£o',
    'eis', 'quis', 'ent√£o', 'am√©m', 'segunda'
])

# Lista de principais figuras b√≠blicas para priorizar na busca
BIG_ENTITIES = [
    'Deus', 'Jesus', 'Senhor', 'Esp√≠rito', 'Mois√©s', 'Ar√£o', 'Fara√≥', 'Josu√©', 
    'Davi', 'Saul', 'Salom√£o', 'Elias', 'Eliseu', 'Isa√≠as', 'Jeremias', 'Ezequiel', 
    'Daniel', 'Pedro', 'Paulo', 'Jo√£o', 'Tiago', 'Maria', 'Jos√©', 'Abra√£o', 
    'Isaque', 'Jac√≥', 'Jos√©', 'Jud√°', 'Pilatos', 'Herodes', 'Judas', 'Tim√≥teo',
    'Barnab√©', 'Silas', 'Tito', 'No√©', 'Ad√£o', 'Eva', 'Caim', 'Abel', 'Golias',
    'Jonas', 'J√≥', 'Samuel', 'Absal√£o', 'Nabucodonosor', 'Calebe'
]

def simple_entity_extractor(text):
    """
    Extrai palavras com inicial mai√∫scula que n√£o est√£o no in√≠cio da frase
    e filtra por uma lista de nomes comuns b√≠blicos.
    """
    if not isinstance(text, str):
        return []
    
    # Limpeza b√°sica
    clean_text = re.sub(r'[^\w\s]', '', text)
    words = clean_text.split()
    
    entities = []
    
    for i, word in enumerate(words):
        # Verifica se √© um dos grandes nomes (independente de posi√ß√£o)
        if word in BIG_ENTITIES:
            entities.append(word)
            continue
            
        # Heur√≠stica: Palavra com mai√∫scula no meio da frase
        if i > 0 and word[0].isupper() and word.lower() not in STOPWORDS_PT:
            if len(word) > 2: # Evita siglas curtas ou erros
                entities.append(word)
                
    return list(set(entities)) # Remove duplicatas no mesmo vers√≠culo

@st.cache_data
def process_entities(df):
    # Aplica a extra√ß√£o
    df['Entidades'] = df['Texto'].apply(simple_entity_extractor)
    return df

@st.cache_data
def generate_reading_plan(df):
    """
    Gera um plano de leitura de 365 dias com cap√≠tulos aleat√≥rios.
    Divide o total de cap√≠tulos por 365 e embaralha a ordem de forma determin√≠stica.
    """
    # Identificar cap√≠tulos √∫nicos
    # Usamos drop_duplicates para pegar a lista √∫nica de (Livro, Capitulo)
    if 'Livro_ID' in df.columns:
        # Ordenamos inicialmente para ter uma base consistente
        chapters = df[['Livro_ID', 'Livro', 'Capitulo']].drop_duplicates().sort_values(['Livro_ID', 'Capitulo'])
    else:
        chapters = df[['Livro', 'Capitulo']].drop_duplicates()
        
    chapters_list = chapters[['Livro', 'Capitulo']].values.tolist()
    total_chapters = len(chapters_list)
    
    # --- L√ìGICA DE ALEATORIEDADE ---
    # Usamos seed(42) para garantir que o plano seja o mesmo para todos os usu√°rios
    # e n√£o mude toda vez que a p√°gina recarregar. O dia 1 ser√° sempre o mesmo "random".
    random.seed(42)
    random.shuffle(chapters_list)
    
    # Cap√≠tulos por dia (distribui√ß√£o proporcional)
    plan = {}
    chunk_size = total_chapters / 365
    
    current_idx = 0
    for day in range(1, 366):
        end_idx = int(day * chunk_size)
        daily_chapters = chapters_list[current_idx:end_idx]
        
        # Como os cap√≠tulos s√£o aleat√≥rios, podemos ter livros misturados.
        # N√£o reordenamos daily_chapters para manter a aleatoriedade pura proposta.
        plan[day] = daily_chapters
        current_idx = end_idx
        
    return plan, total_chapters

# =========================================================
# 2. INTERFACE E NAVEGA√á√ÉO
# =========================================================

st.title("üìñ B√≠blia Analytics & Network")
st.markdown("Uma ferramenta para an√°lise explorat√≥ria, devocional e visualiza√ß√£o de redes no texto sagrado.")

# Sidebar para Upload
st.sidebar.header("Dados")
uploaded_file = st.sidebar.file_uploader("Carregar arquivo da B√≠blia (CSV/Excel)", type=['csv', 'xlsx'])

# Se n√£o tiver arquivo, usar dados de exemplo (mock) ou pedir arquivo
if uploaded_file is not None:
    if uploaded_file.name.endswith('.csv'):
        df = load_data(uploaded_file)
    else:
        # Se for excel, converte
        df = pd.read_excel(uploaded_file)
        cols_map = {'Book Name': 'Livro', 'Book Number': 'Livro_ID', 'Chapter': 'Capitulo', 'Verse': 'Versiculo', 'Text': 'Texto', 'Verse ID': 'ID_Global'}
        df.rename(columns=cols_map, inplace=True, errors='ignore')

    if df is not None:
        with st.spinner('Processando dados...'):
            if 'Entidades' not in df.columns:
                df = process_entities(df)
            
        st.sidebar.success(f"Dados carregados! {len(df)} vers√≠culos.")
        
        # Menu Principal
        menu = st.sidebar.radio("Navega√ß√£o", [
            "Devocional Di√°rio", # Nova primeira op√ß√£o
            "Dashboard Geral", 
            "An√°lise de Entidades", 
            "Redes de Conex√£o (SNA)", 
            "Explorador de Texto",
            "Assistente de Estudo IA"
        ])
        
        # Input de API Key Global (usado em devocional e assistente)
        api_key = ""
        if menu in ["Assistente de Estudo IA", "Devocional Di√°rio"]:
            if HAS_GENAI:
                st.sidebar.markdown("---")
                st.sidebar.markdown("### üîë Configura√ß√£o IA")
                api_key = st.sidebar.text_input("Google Gemini API Key", type="password", help="Obtenha sua chave gratuita no Google AI Studio")

        # ---------------------------------------------------------
        # ABA: DEVOCIONAL DI√ÅRIO (NOVA)
        # ---------------------------------------------------------
        if menu == "Devocional Di√°rio":
            st.header("üôè Devocional Anual (Aleat√≥rio)")
            st.markdown("Acompanhe a leitura da B√≠blia em 365 dias com passagens selecionadas aleatoriamente.")
            
            # Gera plano
            plan, total_chapters = generate_reading_plan(df)
            
            # Controles de Data e Navega√ß√£o
            col_date, col_nav = st.columns([1, 2])
            
            with col_date:
                today = datetime.now()
                selected_date = st.date_input("Selecione a Data", today)
                # Calcula dia do ano (1 a 365/366)
                day_of_year = selected_date.timetuple().tm_yday
                # Ajuste simples para anos bissextos ou limitar a 365
                if day_of_year > 365: day_of_year = 365
            
            # Recupera cap√≠tulos do dia
            todays_chapters = plan.get(day_of_year, [])
            
            with col_nav:
                st.caption(f"Dia {day_of_year} de 365")
                progress = day_of_year / 365
                st.progress(progress)
                if progress == 1.0:
                    st.success("Parab√©ns! Voc√™ completou o ciclo de leitura.")

            if not todays_chapters:
                st.info("Nenhuma leitura programada para hoje (ou fim do plano).")
            else:
                # Formata t√≠tulo da leitura
                reading_refs = []
                for book, chap in todays_chapters:
                    reading_refs.append(f"{book} {chap}")
                
                # Exibe de forma resumida se houver muitos
                if len(reading_refs) > 3:
                    reading_title = ", ".join(reading_refs[:3]) + f" e mais {len(reading_refs)-3}"
                else:
                    reading_title = ", ".join(reading_refs)
                
                st.subheader(f"Leitura de Hoje: {reading_title}")
                
                # Exibir Texto
                tab_texto, tab_reflexao = st.tabs(["üìñ Texto B√≠blico", "ü§ñ Reflex√£o com IA"])
                
                full_text_devocional = ""
                
                with tab_texto:
                    for book, chap in todays_chapters:
                        st.markdown(f"### {book} {chap}")
                        subset = df[(df['Livro'] == book) & (df['Capitulo'] == chap)]
                        text_content = ""
                        for _, row in subset.iterrows():
                            vers = row['Versiculo']
                            txt = row['Texto']
                            text_content += f"{vers}. {txt} "
                            st.markdown(f"**{vers}.** {txt}")
                        full_text_devocional += f"\n\nTexto de {book} {chap}:\n{text_content}"
                        st.divider()
                
                with tab_reflexao:
                    st.markdown("### Gerar Devocional Personalizado")
                    st.write("Use a IA para criar uma reflex√£o curta e uma ora√ß√£o baseada na leitura de hoje.")
                    
                    if st.button("‚ú® Criar Devocional do Dia"):
                        if not HAS_GENAI:
                            st.error("Biblioteca Google GenAI n√£o instalada.")
                        elif not api_key:
                            st.error("Insira sua API Key na barra lateral.")
                        else:
                            try:
                                with st.spinner("Refletindo sobre a palavra..."):
                                    client = genai.Client(api_key=api_key)
                                    prompt_devocional = f"""
                                    Crie um devocional curto e inspirador baseado na leitura b√≠blica de hoje que cont√©m passagens variadas: {reading_title}.
                                    
                                    O texto lido cont√©m os seguintes trechos:
                                    {full_text_devocional[:20000]} ... (texto truncado se muito longo)
                                    
                                    Como as passagens s√£o aleat√≥rias, tente encontrar um fio condutor ou tema comum, ou foque na passagem mais impactante.
                                    
                                    Estrutura desejada:
                                    1. **Vers√≠culo Chave**: Escolha um vers√≠culo impactante dessa leitura.
                                    2. **Reflex√£o**: Um par√°grafo profundo mas aplic√°vel sobre o tema.
                                    3. **Aplica√ß√£o**: Uma a√ß√£o pr√°tica para hoje.
                                    4. **Ora√ß√£o**: Uma ora√ß√£o curta de encerramento.
                                    """
                                    
                                    response = client.models.generate_content(
                                        model='gemini-2.5-flash-lite',
                                        contents=prompt_devocional
                                    )
                                    
                                    st.markdown(response.text)
                            except Exception as e:
                                st.error(f"Erro ao gerar devocional: {e}")

        # ---------------------------------------------------------
        # ABA: DASHBOARD GERAL
        # ---------------------------------------------------------
        elif menu == "Dashboard Geral":
            st.header("Vis√£o Macro")
            
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Total de Livros", df['Livro'].nunique())
            c2.metric("Total de Cap√≠tulos", df.groupby(['Livro', 'Capitulo']).ngroups)
            c3.metric("Total de Vers√≠culos", len(df))
            
            # Contagem de palavras aproximada
            total_words = df['Texto'].astype(str).apply(lambda x: len(x.split())).sum()
            c4.metric("Total de Palavras", f"{total_words:,.0f}".replace(",", "."))
            
            st.subheader("Distribui√ß√£o de Vers√≠culos por Livro")
            verse_counts = df['Livro'].value_counts().reset_index()
            verse_counts.columns = ['Livro', 'Contagem']
            
            # Ordenar pela ordem original b√≠blica (usando ID se dispon√≠vel)
            if 'Livro_ID' in df.columns:
                order_map = df[['Livro', 'Livro_ID']].drop_duplicates().set_index('Livro')['Livro_ID']
                verse_counts['ID'] = verse_counts['Livro'].map(order_map)
                verse_counts = verse_counts.sort_values('ID')
            
            fig = px.bar(verse_counts, x='Livro', y='Contagem', title="Vers√≠culos por Livro")
            st.plotly_chart(fig, use_container_width=True)

        # ---------------------------------------------------------
        # ABA: AN√ÅLISE DE ENTIDADES
        # ---------------------------------------------------------
        elif menu == "An√°lise de Entidades":
            st.header("An√°lise de Personagens e Entidades")
            
            # Flattening the list of entities
            all_entities = [ent for sublist in df['Entidades'] for ent in sublist]
            entity_counts = Counter(all_entities).most_common(50)
            df_ent = pd.DataFrame(entity_counts, columns=['Entidade', 'Frequ√™ncia'])
            
            c1, c2 = st.columns([1, 2])
            
            with c1:
                st.subheader("Top Mencionado")
                st.dataframe(df_ent, height=500)
                
            with c2:
                st.subheader("Frequ√™ncia Visual")
                fig = px.bar(df_ent.head(20), x='Frequ√™ncia', y='Entidade', orientation='h', title="Top 20 Entidades")
                fig.update_layout(yaxis={'categoryorder':'total ascending'})
                st.plotly_chart(fig, use_container_width=True)
                
            st.divider()
            
            # An√°lise Temporal/Posicional
            st.subheader("Onde a Entidade Aparece?")
            
            # Criando lista completa e ordenada de todas as entidades √∫nicas encontradas
            unique_entities_list = sorted(list(set(all_entities)))
            
            selected_entity = st.selectbox("Selecione uma entidade para rastrear:", unique_entities_list)
            
            if selected_entity:
                # Filtrar dataframe
                mask = df['Entidades'].apply(lambda x: selected_entity in x)
                df_filtered = df[mask].copy()
                
                # Criar um √≠ndice sequencial global para o eixo X
                df_filtered['Posicao_Global'] = df_filtered.index
                
                fig_timeline = px.scatter(
                    df_filtered, 
                    x='ID_Global' if 'ID_Global' in df.columns else df_filtered.index, 
                    y='Livro', 
                    hover_data=['Capitulo', 'Versiculo', 'Texto'],
                    title=f"Dispers√£o de '{selected_entity}' ao longo da B√≠blia",
                    color='Livro'
                )
                fig_timeline.update_layout(showlegend=False)
                st.plotly_chart(fig_timeline, use_container_width=True)
                
                with st.expander(f"Ver vers√≠culos com '{selected_entity}'"):
                    st.dataframe(df_filtered[['Livro', 'Capitulo', 'Versiculo', 'Texto']])

        # ---------------------------------------------------------
        # ABA: REDES (SNA)
        # ---------------------------------------------------------
        elif menu == "Redes de Conex√£o (SNA)":
            st.header("An√°lise de Redes Sociais B√≠blica")
            st.markdown("Conex√µes baseadas em co-ocorr√™ncia: **Personagens que aparecem no mesmo vers√≠culo**.")
            
            # --- PREPARA√á√ÉO DOS DADOS ---
            edge_counter = Counter()
            node_counter = Counter()
            
            # Iterar sobre vers√≠culos e criar arestas (feito antes dos filtros para ter o universo completo)
            for entities in df['Entidades']:
                if len(entities) > 1:
                    sorted_ents = sorted(entities)
                    for i in range(len(sorted_ents)):
                        node_counter[sorted_ents[i]] += 1
                        for j in range(i + 1, len(sorted_ents)):
                            edge = (sorted_ents[i], sorted_ents[j])
                            edge_counter[edge] += 1
            
            # --- FILTROS DE INTERFACE ---
            col_filters_1, col_filters_2 = st.columns(2)
            
            with col_filters_1:
                min_weight = st.slider("M√≠nimo de Co-ocorr√™ncias (Peso)", 1, 50, 5)
            
            # Lista de entidades ordenada alfabeticamente para o dropdown
            all_available_nodes = sorted([k for k, v in node_counter.items() if v > 1])
            
            with col_filters_2:
                # Seletor de modo: Vis√£o Geral ou Entidade Espec√≠fica
                focus_option = st.selectbox(
                    "Focar em Entidade Espec√≠fica", 
                    ["Vis√£o Geral (Top Conectados)"] + all_available_nodes
                )

            # Filtro condicional de 'M√°ximo de N√≥s' (s√≥ mostra se for Vis√£o Geral)
            max_nodes = 50
            if focus_option == "Vis√£o Geral (Top Conectados)":
                max_nodes = st.slider("M√°ximo de N√≥s no Grafo", 10, 200, 50)

            # --- CONSTRU√á√ÉO DO GRAFO (G) ---
            G = nx.Graph()
            
            if focus_option == "Vis√£o Geral (Top Conectados)":
                # L√ìGICA ORIGINAL: Filtra pelos TOP N mais frequentes
                top_nodes = [n for n, c in node_counter.most_common(max_nodes)]
                
                for edge, weight in edge_counter.items():
                    if weight >= min_weight:
                        source, target = edge
                        if source in top_nodes and target in top_nodes:
                            G.add_edge(source, target, weight=weight)
                            G.add_node(source, size=node_counter[source])
                            G.add_node(target, size=node_counter[target])
                            
            else:
                # NOVA L√ìGICA: Rede Egoc√™ntrica (Foco na entidade selecionada)
                target_entity = focus_option
                
                # Adiciona o n√≥ central
                G.add_node(target_entity, size=node_counter[target_entity])
                
                # Busca vizinhos conectados a esta entidade
                found_connections = False
                for edge, weight in edge_counter.items():
                    if weight >= min_weight:
                        if target_entity in edge:
                            found_connections = True
                            # Identifica quem √© o vizinho
                            neighbor = edge[1] if edge[0] == target_entity else edge[0]
                            
                            G.add_edge(target_entity, neighbor, weight=weight)
                            G.add_node(neighbor, size=node_counter[neighbor])
                
                if not found_connections:
                    st.warning(f"A entidade '{target_entity}' n√£o tem conex√µes com peso >= {min_weight}.")

            # --- VISUALIZA√á√ÉO ---
            if len(G.nodes) > 0:
                c1, c2, c3 = st.columns(3)
                c1.metric("N√≥s (Entidades)", len(G.nodes))
                c2.metric("Arestas (Conex√µes)", len(G.edges))
                density = nx.density(G)
                c3.metric("Densidade", f"{density:.4f}")
                
                # Layout do Grafo
                pos = nx.spring_layout(G, k=0.5, seed=42)
                
                edge_x = []
                edge_y = []
                for edge in G.edges():
                    x0, y0 = pos[edge[0]]
                    x1, y1 = pos[edge[1]]
                    edge_x.append(x0)
                    edge_x.append(x1)
                    edge_x.append(None)
                    edge_y.append(y0)
                    edge_y.append(y1)
                    edge_y.append(None)

                edge_trace = go.Scatter(
                    x=edge_x, y=edge_y,
                    line=dict(width=0.5, color='#888'),
                    hoverinfo='none',
                    mode='lines')

                node_x = []
                node_y = []
                node_text = []
                node_size = []
                node_colors = [] # Para colorir diferente o n√≥ central se houver foco
                
                for node in G.nodes():
                    x, y = pos[node]
                    node_x.append(x)
                    node_y.append(y)
                    node_text.append(f"{node} (Men√ß√µes: {G.nodes[node].get('size', 0)})")
                    
                    # Tamanho
                    sz = G.nodes[node].get('size', 10)
                    node_size.append(min(50, max(10, sz / 5)))
                    
                    # Cor (L√≥gica para destacar o selecionado)
                    if focus_option != "Vis√£o Geral (Top Conectados)" and node == focus_option:
                        node_colors.append(1000) # Valor alto para cor diferente
                    else:
                        # Cor baseada no grau (conectividade)
                        node_colors.append(len(list(G.neighbors(node))))

                node_trace = go.Scatter(
                    x=node_x, y=node_y,
                    mode='markers+text',
                    hoverinfo='text',
                    text=[node for node in G.nodes()],
                    textposition="top center",
                    marker=dict(
                        showscale=True,
                        colorscale='YlGnBu',
                        reversescale=True,
                        color=node_colors,
                        size=node_size,
                        colorbar=dict(
                            thickness=15,
                            title='Conectividade',
                            xanchor='left',
                        ),
                        line_width=2))
                
                fig_net = go.Figure(data=[edge_trace, node_trace],
                             layout=go.Layout(
                                title=dict(
                                    text=f'Rede: {focus_option}',
                                    font=dict(size=16)
                                ),
                                showlegend=False,
                                hovermode='closest',
                                margin=dict(b=20,l=5,r=5,t=40),
                                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))
                                )
                st.plotly_chart(fig_net, use_container_width=True)
                
                st.info("Dica: Use zoom no gr√°fico para explorar clusters espec√≠ficos.")

            else:
                st.warning("Nenhuma conex√£o encontrada com os filtros atuais.")

        # ---------------------------------------------------------
        # ABA: EXPLORADOR
        # ---------------------------------------------------------
        elif menu == "Explorador de Texto":
            st.header("Leitura e Pesquisa")
            
            search_term = st.text_input("Pesquisar no texto (ex: 'amor', 'luz', 'espada')")
            
            if search_term:
                results = df[df['Texto'].str.contains(search_term, case=False, na=False)]
                st.write(f"Encontrados **{len(results)}** vers√≠culos contendo '{search_term}'.")
                st.dataframe(results[['Livro', 'Capitulo', 'Versiculo', 'Texto']], height=400)
            
            st.divider()
            
            c_livro, c_cap = st.columns(2)
            livro_sel = c_livro.selectbox("Livro", df['Livro'].unique())
            
            caps_disponiveis = df[df['Livro'] == livro_sel]['Capitulo'].unique()
            cap_sel = c_cap.selectbox("Cap√≠tulo", sorted(caps_disponiveis))
            
            texto_capitulo = df[(df['Livro'] == livro_sel) & (df['Capitulo'] == cap_sel)]
            
            st.subheader(f"{livro_sel} {cap_sel}")
            for _, row in texto_capitulo.iterrows():
                # Destacar entidades no texto se houver
                texto_fmt = row['Texto']
                for ent in row['Entidades']:
                    texto_fmt = texto_fmt.replace(ent, f"**{ent}**")
                    
                st.markdown(f"**{row['Versiculo']}.** {texto_fmt}")
        
        # ---------------------------------------------------------
        # ABA: ASSISTENTE DE ESTUDO IA (ATUALIZADA)
        # ---------------------------------------------------------
        elif menu == "Assistente de Estudo IA":
            st.header("ü§ñ Assistente de Estudo B√≠blico (IA)")
            st.markdown("""
            Utilize a intelig√™ncia artificial para obter insights teol√≥gicos, 
            contexto hist√≥rico e aplica√ß√µes pr√°ticas do texto selecionado.
            """)
            
            # Verifica√ß√£o de depend√™ncia
            if not HAS_GENAI:
                st.error("‚ö†Ô∏è A biblioteca `google-genai` n√£o foi encontrada.")
                st.info("Para usar esta fun√ß√£o, instale a biblioteca adicionando `google-genai` ao seu arquivo `requirements.txt`.")
                st.stop()
            
            if not api_key:
                st.warning("Insira sua API Key na barra lateral para usar o assistente.")

            # Sele√ß√£o do Texto
            c1, c2, c3 = st.columns(3)
            
            livro_sel = c1.selectbox("Livro", df['Livro'].unique(), key='ia_livro')
            
            caps_disponiveis = df[df['Livro'] == livro_sel]['Capitulo'].unique()
            cap_sel = c2.selectbox("Cap√≠tulo", sorted(caps_disponiveis), key='ia_cap')
            
            # Vers√≠culos (Op√ß√£o de "Todos" ou espec√≠fico)
            versiculos_disponiveis = df[(df['Livro'] == livro_sel) & (df['Capitulo'] == cap_sel)]['Versiculo'].unique()
            versiculos_com_todos = ["Todos"] + list(sorted(versiculos_disponiveis))
            vers_sel = c3.selectbox("Vers√≠culo", versiculos_com_todos, key='ia_vers')
            
            # Recuperar texto
            if vers_sel == "Todos":
                texto_df = df[(df['Livro'] == livro_sel) & (df['Capitulo'] == cap_sel)]
                texto_completo = " ".join(texto_df['Texto'].astype(str).tolist())
                referencia = f"{livro_sel} {cap_sel}"
            else:
                texto_df = df[(df['Livro'] == livro_sel) & (df['Capitulo'] == cap_sel) & (df['Versiculo'] == vers_sel)]
                if not texto_df.empty:
                    texto_completo = texto_df.iloc[0]['Texto']
                    referencia = f"{livro_sel} {cap_sel}:{vers_sel}"
                else:
                    texto_completo = ""
                    referencia = ""

            # Exibir Texto Selecionado
            with st.expander("üìñ Ler Texto Selecionado", expanded=True):
                st.info(f"**{referencia}**: {texto_completo}")

            # Bot√£o de A√ß√£o
            if st.button("üîç Analisar com IA", type="primary"):
                if not api_key:
                    st.error("Por favor, insira a API Key na barra lateral.")
                elif not texto_completo:
                    st.error("Texto n√£o encontrado.")
                else:
                    try:
                        with st.spinner("A IA est√° analisando as escrituras (usando Gemini 2.0)..."):
                            # =========================================================
                            # ATUALIZA√á√ÉO PARA GOOGLE-GENAI (V1 SDK)
                            # =========================================================
                            
                            # Inicializa√ß√£o do Cliente
                            client = genai.Client(api_key=api_key)
                            
                            prompt = f"""
                            Atue como um especialista em teologia b√≠blica, hist√≥ria e hermen√™utica.
                            Analise o seguinte texto b√≠blico:
                            
                            Refer√™ncia: {referencia}
                            Texto: "{texto_completo}"
                            
                            Por favor, forne√ßa:
                            1. **Contexto Hist√≥rico e Liter√°rio**: O que estava acontecendo na √©poca? Quem escreveu e para quem?
                            2. **Explica√ß√£o Teol√≥gica**: Qual o significado profundo deste trecho?
                            3. **Aplica√ß√£o Pr√°tica**: Como aplicar este ensinamento nos dias de hoje?
                            
                            Seja profundo mas acess√≠vel. Formate a resposta usando Markdown.
                            """
                            
                            # Chamada ao modelo
                            response = client.models.generate_content(
                                model='gemini-2.5-flash-lite',
                                contents=prompt
                            )
                            
                            st.markdown("---")
                            st.markdown(response.text)
                            st.success("An√°lise conclu√≠da!")
                            
                    except Exception as e:
                        st.error(f"Ocorreu um erro ao conectar com a IA: {e}")

else:
    st.info("Por favor, fa√ßa o upload do arquivo 'blivre.xlsx' ou CSV na barra lateral para come√ßar.")
    st.markdown("""
    ### Instru√ß√µes:
    1. Arraste o arquivo `blivre.xlsx` para a √°rea de upload √† esquerda.
    2. Aguarde o processamento inicial.
    3. Navegue pelas abas para explorar as vis√µes anal√≠ticas.
    """)
